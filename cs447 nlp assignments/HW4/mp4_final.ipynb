{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of MP4_bak.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gau9xEXMGY8s",
        "colab_type": "text"
      },
      "source": [
        "# Using Attention for Neural Machine Translation\n",
        "In this notebook we are going to perform machine translation using a deep learning based approach and attention mechanism.\n",
        "\n",
        "Specifically, we are going to train a sequence to sequence model for Spanish to English translation.  We will use Sequence to Sequence Models for this Assignment. In this assignment you only need tto implement the encoder and decoder, we implement all the data loading for you.Please **refer** to the following resources for more details:\n",
        "\n",
        "1.   https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf\n",
        "2.   https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
        "3. https://arxiv.org/pdf/1409.0473.pdf\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9mf5x3zHp1A",
        "colab_type": "code",
        "outputId": "b2f4be3b-905c-479f-f73c-8023230b298f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "import torch.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import unicodedata\n",
        "import re\n",
        "import time\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "print(torch.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XH8nu0ojQpt",
        "colab_type": "text"
      },
      "source": [
        "# Download The Data\n",
        "\n",
        "Here we will download the translation data. We will learn a model to translate Spanish to English."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftasb3wEH0gC",
        "colab_type": "code",
        "outputId": "4680fe39-7869-43af-a852-427012444e01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j41KgqCVIIjp",
        "colab_type": "code",
        "outputId": "02d1044f-ef4d-467c-82c8-b50758017319",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd sample_data/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtyBFlMKIg7g",
        "colab_type": "code",
        "outputId": "b142ee27-f24b-43d1-b9ae-156ff3670ad1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget http://www.manythings.org/anki/spa-eng.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-06 22:38:47--  http://www.manythings.org/anki/spa-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 104.24.109.196, 104.24.108.196, 2606:4700:30::6818:6cc4, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|104.24.109.196|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4752884 (4.5M) [application/zip]\n",
            "Saving to: ‘spa-eng.zip’\n",
            "\n",
            "spa-eng.zip         100%[===================>]   4.53M  6.32MB/s    in 0.7s    \n",
            "\n",
            "2019-12-06 22:38:48 (6.32 MB/s) - ‘spa-eng.zip’ saved [4752884/4752884]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGnC0q_SI5qW",
        "colab_type": "code",
        "outputId": "f5802001-975b-4ef4-ce07-c22cee8c2195",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!unzip spa-eng.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  spa-eng.zip\n",
            "  inflating: _about.txt              \n",
            "  inflating: spa.txt                 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC4Pg0kgLxqx",
        "colab_type": "code",
        "outputId": "05555fe4-19c5-4c47-ea65-ed5cbddbfa55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "f = open('spa.txt', encoding='UTF-8').read().strip().split('\\n')\n",
        "lines = f\n",
        "total_num_examples = 30000 \n",
        "original_word_pairs = [[w for w in l.split('\\t')][:2] for l in lines[:total_num_examples]]\n",
        "data = pd.DataFrame(original_word_pairs, columns=[\"eng\", \"es\"])\n",
        "data # visualizing the data"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>es</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Ve.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Vete.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Vaya.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Váyase.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Hola.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29995</th>\n",
              "      <td>Stop blaming yourself.</td>\n",
              "      <td>Deja de culparte a ti mismo.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29996</th>\n",
              "      <td>Summer has just begun.</td>\n",
              "      <td>El verano acaba de comenzar.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29997</th>\n",
              "      <td>Tadpoles become frogs.</td>\n",
              "      <td>Los renacuajos se convierten en ranas.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29998</th>\n",
              "      <td>Take a walk every day.</td>\n",
              "      <td>Da un paseo cada día.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29999</th>\n",
              "      <td>Take care of yourself.</td>\n",
              "      <td>Cuídate.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                          eng                                      es\n",
              "0                         Go.                                     Ve.\n",
              "1                         Go.                                   Vete.\n",
              "2                         Go.                                   Vaya.\n",
              "3                         Go.                                 Váyase.\n",
              "4                         Hi.                                   Hola.\n",
              "...                       ...                                     ...\n",
              "29995  Stop blaming yourself.            Deja de culparte a ti mismo.\n",
              "29996  Summer has just begun.            El verano acaba de comenzar.\n",
              "29997  Tadpoles become frogs.  Los renacuajos se convierten en ranas.\n",
              "29998  Take a walk every day.                   Da un paseo cada día.\n",
              "29999  Take care of yourself.                                Cuídate.\n",
              "\n",
              "[30000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_WR8vEGMQyS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converts the unicode file to ascii\n",
        "def unicode_to_ascii(s):\n",
        "    \"\"\"\n",
        "    Normalizes latin chars with accent to their canonical decomposition\n",
        "    \"\"\"\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "# Preprocessing the sentence to add the start, end tokens and make them lower-case\n",
        "def preprocess_sentence(w):\n",
        "    w = unicode_to_ascii(w.lower().strip())\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "    \n",
        "    w = w.rstrip().strip()\n",
        "    w = '<start> ' + w + ' <end>'\n",
        "    return w"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mud7HbQUMUHB",
        "colab_type": "code",
        "outputId": "79cade43-044c-4fcb-908a-38e90da1b3c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "# Now we do the preprocessing using pandas and lambdas\n",
        "# Make sure YOU only run this once - if you run it twice it will mess up the data so you will have run the few above cells again\n",
        "data[\"eng\"] = data.eng.apply(lambda w: preprocess_sentence(w))\n",
        "data[\"es\"] = data.es.apply(lambda w: preprocess_sentence(w))\n",
        "data[250:260]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>es</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>250</th>\n",
              "      <td>&lt;start&gt; be brief . &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; se breve . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>&lt;start&gt; be brief . &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; sea breve . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>252</th>\n",
              "      <td>&lt;start&gt; be brief . &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; sean breves . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253</th>\n",
              "      <td>&lt;start&gt; be quiet . &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; estate quieto . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>254</th>\n",
              "      <td>&lt;start&gt; be still . &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; no te muevas . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>255</th>\n",
              "      <td>&lt;start&gt; call tom . &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; llamalo a tomas ! &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>256</th>\n",
              "      <td>&lt;start&gt; call tom . &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; llamalo a tomas ! &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>&lt;start&gt; call tom . &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; llamenlo a tomas ! &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>&lt;start&gt; cheer up ! &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; animate . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>&lt;start&gt; cheer up . &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; venga . &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          eng                                es\n",
              "250  <start> be brief . <end>          <start> se breve . <end>\n",
              "251  <start> be brief . <end>         <start> sea breve . <end>\n",
              "252  <start> be brief . <end>       <start> sean breves . <end>\n",
              "253  <start> be quiet . <end>     <start> estate quieto . <end>\n",
              "254  <start> be still . <end>      <start> no te muevas . <end>\n",
              "255  <start> call tom . <end>   <start> llamalo a tomas ! <end>\n",
              "256  <start> call tom . <end>   <start> llamalo a tomas ! <end>\n",
              "257  <start> call tom . <end>  <start> llamenlo a tomas ! <end>\n",
              "258  <start> cheer up ! <end>           <start> animate . <end>\n",
              "259  <start> cheer up . <end>             <start> venga . <end>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHJw_CyykmMp",
        "colab_type": "text"
      },
      "source": [
        "# Vocabulary Class\n",
        "\n",
        "We create a class here for managing our vocabulary as we did in MP2. In this MP, we have a separate class for the vocabulary as we need 2 different vocabularies - one for English and one for Spanish."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1h4Q21azMW-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Vocab_Lang():\n",
        "    def __init__(self, data):\n",
        "        \"\"\" data is the list of all sentences in the language dataset\"\"\"\n",
        "        self.data = data\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.vocab = set()\n",
        "        \n",
        "        self.create_index()\n",
        "        \n",
        "    def create_index(self):\n",
        "        for sentence in self.data:\n",
        "            # update with individual tokens\n",
        "            self.vocab.update(sentence.split(' '))\n",
        "\n",
        "        # add a padding token\n",
        "        self.word2idx['<pad>'] = 0\n",
        "        \n",
        "        # word to index mapping\n",
        "        for index, word in enumerate(self.vocab):\n",
        "            self.word2idx[word] = index + 1 # +1 because of pad token\n",
        "        \n",
        "        # index to word mapping\n",
        "        for word, index in self.word2idx.items():\n",
        "            self.idx2word[index] = word "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWiv0o-8MmXb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# index language using the class above\n",
        "inp_lang = Vocab_Lang(data[\"es\"].values.tolist())\n",
        "targ_lang = Vocab_Lang(data[\"eng\"].values.tolist())\n",
        "# Vectorize the input and target languages\n",
        "input_tensor = [[inp_lang.word2idx[s] for s in es.split(' ')]  for es in data[\"es\"].values.tolist()]\n",
        "target_tensor = [[targ_lang.word2idx[s] for s in eng.split(' ')]  for eng in data[\"eng\"].values.tolist()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bsMZzw4MqJC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SCw4JM-Mrud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate the max_length of input and output tensor for padding\n",
        "max_length_inp, max_length_tar = max_length(input_tensor), max_length(target_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SRtlYCdMtSV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_sequences(x, max_len):\n",
        "    padded = np.zeros((max_len), dtype=np.int64)\n",
        "    if len(x) > max_len: padded[:] = x[:max_len]\n",
        "    else: padded[:len(x)] = x\n",
        "    return padded\n",
        "\n",
        "# pad all the sentences in the dataset with the max_length\n",
        "input_tensor = [pad_sequences(x, max_length_inp) for x in input_tensor]\n",
        "target_tensor = [pad_sequences(x, max_length_tar) for x in target_tensor]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5YR39L9MwLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating training and test/val sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = input_tensor[:24000], input_tensor[24000:], target_tensor[:24000], target_tensor[24000:]\n",
        "\n",
        "assert(len(input_tensor_train)==24000)\n",
        "assert(len(target_tensor_train)==24000)\n",
        "assert(len(input_tensor_val)==6000)\n",
        "assert(len(target_tensor_val)==6000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a2c34aFnPOP",
        "colab_type": "text"
      },
      "source": [
        "# Dataloader for our Encoder and Decoder\n",
        "\n",
        "We prepare the dataloader and make sure the dataloader returns the source sentence, target sentence and the length of the source sentenc sampled from the training dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c797aZAWMzrW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# conver the data to tensors and pass to the Dataloader \n",
        "# to create an batch iterator\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "class MyData(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.data = X\n",
        "        self.target = y\n",
        "        # TODO: convert this into torch code is possible\n",
        "        self.length = [ np.sum(1 - np.equal(x, 0)) for x in X]\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index]\n",
        "        x_len = self.length[index]\n",
        "        return x,y,x_len\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwlsuoMSM1uQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 60\n",
        "N_BATCH = BUFFER_SIZE//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word2idx)\n",
        "vocab_tar_size = len(targ_lang.word2idx)\n",
        "\n",
        "train_dataset = MyData(input_tensor_train, target_tensor_train)\n",
        "val_dataset = MyData(input_tensor_val, target_tensor_val)\n",
        "\n",
        "dataset = DataLoader(train_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)\n",
        "\n",
        "val_dataset = DataLoader(val_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENeT1fj_2f8t",
        "colab_type": "text"
      },
      "source": [
        "# Encoder Model\n",
        "\n",
        "First we build a simple encoder model, which will be very similar to what you did in MP2. But instead of using a fully connected layer as the output, you should the return the output of your recurrent net (GRU/LSTM) as well as the hidden output. They are used in the decoder later.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Sx4QQd3M4XK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Feel free to change any parameters class definitions as long as you can change the training code, but make sure\n",
        "## evaluation should get the tensor format it expects\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz, max_len):\n",
        "        super(Encoder, self).__init__()\n",
        "        # input hyperparameters here:\n",
        "        global NUM_LAYERS, BIDIRECTIONAL, DROPOUT, HIDDEN_DIM\n",
        "        self.num_layers = NUM_LAYERS\n",
        "        self.bidirectional = BIDIRECTIONAL\n",
        "        self.num_directions = 2 if BIDIRECTIONAL else 1\n",
        "        self.dropout = DROPOUT\n",
        "        self.hidden_dim = HIDDEN_DIM\n",
        "        self.max_len = max_len\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.enc_units = enc_units\n",
        "        self.batch_sz = batch_sz\n",
        "        self.embeds = nn.Embedding(vocab_size, embedding_dim, 0)\n",
        "        self.lstm = nn.LSTM(input_size = embedding_dim, hidden_size = HIDDEN_DIM, num_layers = NUM_LAYERS, dropout = DROPOUT, bidirectional = BIDIRECTIONAL, batch_first=True)\n",
        "        self.hidden = None\n",
        "        self.c = None\n",
        "        \n",
        "    def forward(self, x, lens):\n",
        "        '''\n",
        "        Pseudo-code\n",
        "        - Pass x through an embedding layer\n",
        "        - Make sure x is correctly packed before the recurrent net \n",
        "        - Pass it through the recurrent net\n",
        "        - Make sure the output is unpacked correctly\n",
        "        - return output and hidden states from the recurrent net\n",
        "        - Feel free to play around with dimensions - the training loop should help you determine the dimensions\n",
        "        '''\n",
        "        #x = [batch size, MAX LEN]\n",
        "        #lens = [batch size]\n",
        "        embeds = self.embeds(x) # torch.Size([max_len, batch_size, embedding_dim])\n",
        "        # Embedding dimensions: torch.Size([16, 60, 256])\n",
        "\n",
        "        embeds = embeds.permute(1, 0, 2) # torch.Size([batch_size, max_len, embedding_dim])\n",
        "\n",
        "        embeds = nn.utils.rnn.pack_padded_sequence(embeds, lens, batch_first=True, enforce_sorted=False).float()\n",
        "        embeds.to(device)\n",
        "\n",
        "        # pass input through recurrent net\n",
        "        if self.hidden is None:\n",
        "          lstm_out, (self.hidden, self.c) = self.lstm(embeds)\n",
        "        else:\n",
        "          lstm_out, (self.hidden, self.c) = self.lstm(embeds, (self.hidden, self.c))\n",
        "        lstm_out, out_lens = nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=True, total_length=self.max_len)\n",
        "        # lstm_out dimensions: torch.Size([60, 16, 256])\n",
        "        # hidden dimensions: torch.Size([4, 60, 256])\n",
        "\n",
        "        #hidden = [n_layers*num_directions, batch_size, hidden_dim]\n",
        "        #c = [n_layers*num_directions, batch_size, hidden_dim]\n",
        "        #lstm_out = [batch_size, MAX_LEN, hidden_dim*num_directions]\n",
        "        #out_lens = text_lengths\n",
        "\n",
        "        # need to provide both last hidden state and output array to decoder      \n",
        "\n",
        "        # need to translate hidden from 8*batch_size*self.hidden_dim \n",
        "        # to 4 * 1 * self.hidden_dim*2 if we're doing bidirectional lstm\n",
        "        hidden = (self.hidden, self.c)\n",
        "        if self.bidirectional:\n",
        "          hidden = tuple([self.format_bidirectional_shape(self.hidden),self.format_bidirectional_shape(self.c)])\n",
        "        \n",
        "        '''\n",
        "        print(\"Encoder output shape:\",lstm_out.shape)\n",
        "        print(\"Encoder hidden shape:\",self.hidden.shape)\n",
        "        print(\"Encoder c shape:\",self.c.shape)\n",
        "        '''\n",
        "\n",
        "        return lstm_out, hidden\n",
        "\n",
        "    @staticmethod\n",
        "    def format_bidirectional_shape(h):\n",
        "        return torch.cat([h[0:h.size(0):2], h[1:h.size(0):2]], 2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKwsEWpK2mcT",
        "colab_type": "text"
      },
      "source": [
        "# Decoder Model\n",
        "We will implement a Decoder model which uses an attention mechanism. We will implement the decoder as provided in https://arxiv.org/pdf/1409.0473.pdf. **Please read** the links provided above first, at the start of this assignment for review. The pseudo-code for your implementation should be somewhat as follows:\n",
        "\n",
        "\n",
        "\n",
        "1.   The input is put through an encoder model which gives us the encoder output of shape *(batch_size, max_length, hidden_size)* and the encoder hidden state of shape *(batch_size, hidden_size)*. \n",
        "2.   Using the output your encoder you will calculate the score and subsequently the attention using following equations : \n",
        "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_equation_0.jpg\" alt=\"attention equation 0\" width=\"800\">\n",
        "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_equation_1.jpg\" alt=\"attention equation 1\" width=\"800\">\n",
        "\n",
        "3. Once you have calculated this attention vector, you pass the original input x through a embedding layer. The output of this embedding layer is concatenated with the attention vector which is passed into a GRU.\n",
        "\n",
        "4. Finally you pass the output of the GRU into a fully connected layer with an output size same as that vocab, to see the probability of the most possible word.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw84M2LPM-PC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "## Feel free to change any parameters class definitions as long as you can change the training code, but make sure\n",
        "## evaluation should get the tensor format it expects\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, enc_units, batch_sz, tar_len, src_len):\n",
        "        '''                8029         256           1024      1024      60     '''\n",
        "        super(Decoder, self).__init__()\n",
        "        #print(\"Decoder parameters:\", vocab_size, embedding_dim, dec_units, enc_units, batch_sz)\n",
        "        # import hyperparameters here:\n",
        "        global NUM_LAYERS, DROPOUT, HIDDEN_DIM, BIDIRECTIONAL\n",
        "        self.num_layers = NUM_LAYERS\n",
        "        self.dropout_val = DROPOUT\n",
        "        self.hidden_dim = HIDDEN_DIM\n",
        "        self.bidirectional = BIDIRECTIONAL\n",
        "        num_directions = 2 if self.bidirectional else 1\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.enc_units = enc_units\n",
        "        self.batch_sz = batch_sz\n",
        "        self.tar_len = tar_len\n",
        "        self.src_len = src_len\n",
        "        \n",
        "        self.embeds = nn.Embedding(vocab_size, embedding_dim, 0)\n",
        "        self.lstm = nn.LSTM(input_size = embedding_dim, hidden_size = HIDDEN_DIM, num_layers = NUM_LAYERS, dropout = self.dropout_val, bidirectional = BIDIRECTIONAL, batch_first=True)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "        self.dropout = nn.Dropout(self.dropout_val)\n",
        "\n",
        "        \n",
        "        self.W1 = nn.Linear(self.hidden_dim * num_directions, self.hidden_dim, bias=False)\n",
        "        self.W2 = nn.Linear(self.hidden_dim * num_directions, self.hidden_dim, bias=False)\n",
        "        self.W3 = nn.Linear(self.hidden_dim * num_directions, 1, bias=False)\n",
        "        \n",
        "        self.hidden_to_vocab_size = nn.Linear(self.embedding_dim, self.vocab_size, bias=False)\n",
        "        \n",
        "    \n",
        "    def forward(self, x, decoder_hidden, enc_output):#, src_lens):\n",
        "        '''\n",
        "        Pseudo-code\n",
        "        - Calculate the score using the formula shown above using encoder output and hidden output. \n",
        "        Note h_t is the hidden output of the decoder and h_s is the encoder output in the formula\n",
        "        - Calculate the attention weights using softmax and passing through V - which can be implemented as a fully connected layer\n",
        "        - Finally find c_t which is a context vector where the shape of context_vector should be (batch_size, hidden_size)\n",
        "        - You need to unsqueeze the context_vector for concatenating with x as listed in Point 3 above\n",
        "        - Pass this concatenated tensor to the GRU and follow as specified in Point 4 above\n",
        "\n",
        "        x          : [60, 1]\n",
        "        enc_output : [60, 16, 256]\n",
        "        hidden[0]  : [4, 60, 256]\n",
        "        hidden[1]  : [4, 60, 256]\n",
        "        '''\n",
        "\n",
        "        # last_layer_hidden == (batch_size, 1, hidden_size)\n",
        "        last_layer_hidden = decoder_hidden[0][-1]\n",
        "        last_layer_hidden = last_layer_hidden.unsqueeze(1)\n",
        "\n",
        "        # score shape == (batch_size, max_length, hidden_size)\n",
        "        score = torch.tanh(self.W1(enc_output) + self.W2(last_layer_hidden))\n",
        "\n",
        "        # attention_weights shape == (batch_size, max_length, 1)\n",
        "        # we get 1 at the last axis because we are applying score to self.W3\n",
        "        attention_weights = self.softmax(self.W3(score))\n",
        "\n",
        "        # context_vector shape after sum == (batch_size, hidden_size)\n",
        "        context_vector = attention_weights * enc_output # torch.Size([batch_size, max_len, hidden_size])\n",
        "        context_vector = torch.sum(context_vector, 1) # torch.Size([batch_size, hidden_size])\n",
        "\n",
        "        #x = [batch size, 1]\n",
        "        #lens = [batch size]\n",
        "        # embeds shape == (batch_size, 1, hidden_size)\n",
        "        embeds = self.embeds(x.long())\n",
        "        embeds.to(device)\n",
        "        \n",
        "        # pass embeddings modified with attention vectors through recurrent decoder net\n",
        "        # decoder_out shape == (batch_size, vocab_size)\n",
        "        # decoder_hidden shape == (num_layers, batch_size, hidden_size)\n",
        "        decoder_out, decoder_hidden = self.lstm(embeds, decoder_hidden)\n",
        "        \"\"\"\n",
        "        Decoder output is of shape torch.Size([60, 1, 256])\n",
        "        Decoder hidden state is of shape torch.Size([4, 60, 256])\n",
        "        Decoder c state is of shape torch.Size([4, 60, 256])\n",
        "        \"\"\"\n",
        "        decoder_out = decoder_out.squeeze(1)\n",
        "        decoder_out = self.hidden_to_vocab_size(decoder_out)       \n",
        "        attention_weights = attention_weights.squeeze(2)\n",
        "\n",
        "        \"        Returns :\"\n",
        "        \"        output - shape = (batch_size, vocab)\"\n",
        "        \"        hidden state - shape = (num_layers*num_dimensions, batch_size, hidden size)\"\n",
        "        \"        attention weights - shape = (batch_size, max_src_len)\"\n",
        "\n",
        "        return decoder_out, decoder_hidden, attention_weights\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxYamsE3M6u6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### sort batch function to be able to use with pad_packed_sequence\n",
        "def sort_batch(X, y, lengths):\n",
        "    lengths, indx = lengths.sort(dim=0, descending=True)\n",
        "    X = X[indx]\n",
        "    y = y[indx]\n",
        "    return X.transpose(0,1), y, lengths # transpose (batch x seq) to (seq x batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bp2rKJY4NIzx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    \"\"\" Only consider non-zero inputs in the loss; mask needed \"\"\"\n",
        "    mask = 1 - np.equal(real, 0) # assign 0 to all above 0 and 1 to all 0s\n",
        "    #print(mask)\n",
        "    #mask = real.ge(1).type(torch.cuda.FloatTensor)\n",
        "    \n",
        "    loss_ = criterion(pred, real) * mask \n",
        "    return torch.mean(loss_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjbsUkcpNK9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# hyperparameters\n",
        "NUM_LAYERS = 4\n",
        "BIDIRECTIONAL = False\n",
        "DROPOUT = 0.1\n",
        "HIDDEN_DIM = embedding_dim\n",
        "BIAS = True\n",
        "\n",
        "## Feel free to change any parameters class definitions as long as you can change the training code, but make sure\n",
        "## evaluation should get the tensor format it expects, this is only for reference\n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE, max_length_inp)\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, units, BATCH_SIZE, max_length_inp, max_length_tar)\n",
        "\n",
        "encoder.to(device)\n",
        "decoder.to(device)\n",
        "\n",
        "optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), \n",
        "                       lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaH022cEy03q",
        "colab_type": "text"
      },
      "source": [
        "# Train your model\n",
        "\n",
        "You will train your model here.\n",
        "*   Pass the source sentence and their corresponding lengths into the encoder\n",
        "*   Creating the decoder input using <start> tokens\n",
        "*   Now we find out the decoder outputs conditioned on the previous predicted word usually, but in our training we use teacher forcing. Read more about teacher forcing at https://machinelearningmastery.com/teacher-forcing-for-recurrent-neural-networks/\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9663UYJNMgv",
        "colab_type": "code",
        "outputId": "2d3de533-fa5f-4802-8511-1d95d2c2038a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "encoder.train()\n",
        "decoder.train()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    \n",
        "    total_loss = 0\n",
        "    \n",
        "    for (batch, (inp, targ, inp_len)) in enumerate(dataset):\n",
        "        loss = 0\n",
        "        \n",
        "        xs, ys, lens = sort_batch(inp, targ, inp_len)\n",
        "        enc_output, enc_hidden = encoder(xs.to(device), lens)\n",
        "        dec_hidden = enc_hidden\n",
        "        #dec_hidden[0].to(device)\n",
        "        #dec_hidden[1].to(device) # tuple has no attribute '.to(device)'\n",
        "        \n",
        "        # use teacher forcing - feeding the target as the next input (via dec_input)\n",
        "        dec_input = torch.tensor([[targ_lang.word2idx['<start>']]] * BATCH_SIZE)\n",
        "        \n",
        "        # run code below for every timestep in the ys batch\n",
        "        for t in range(1, ys.size(1)):\n",
        "            predictions, dec_hidden, _ = decoder(dec_input.to(device), \n",
        "                                         dec_hidden, \n",
        "                                         enc_output.to(device))\n",
        "            \n",
        "            loss += loss_function(ys[:, t].to(device), predictions.to(device))\n",
        "            \n",
        "            dec_input = ys[:, t].unsqueeze(1)\n",
        "            \n",
        "        encoder.hidden.detach_()\n",
        "        encoder.c.detach_()\n",
        "        encoder.hidden = encoder.hidden.detach()\n",
        "        encoder.c = encoder.c.detach()\n",
        "        \n",
        "        batch_loss = (loss / int(ys.size(1)))\n",
        "        total_loss += batch_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        loss.backward()\n",
        "\n",
        "        ### UPDATE MODEL PARAMETERS\n",
        "        optimizer.step()\n",
        "\n",
        "        \n",
        "        \n",
        "        if batch % 100 == 0:\n",
        "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                         batch,\n",
        "                                                         batch_loss.detach().item()))\n",
        "        \n",
        "        \n",
        "    ### TODO: Save checkpoint for model\n",
        "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                        total_loss / N_BATCH))\n",
        "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
        "    "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 2.4912\n",
            "Epoch 1 Batch 100 Loss 2.2049\n",
            "Epoch 1 Batch 200 Loss 2.0012\n",
            "Epoch 1 Batch 300 Loss 1.9407\n",
            "Epoch 1 Loss 2.0152\n",
            "Time taken for 1 epoch 282.5075783729553 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.8202\n",
            "Epoch 2 Batch 100 Loss 1.5993\n",
            "Epoch 2 Batch 200 Loss 1.4232\n",
            "Epoch 2 Batch 300 Loss 1.5229\n",
            "Epoch 2 Loss 1.5777\n",
            "Time taken for 1 epoch 281.60485434532166 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.4456\n",
            "Epoch 3 Batch 100 Loss 1.2187\n",
            "Epoch 3 Batch 200 Loss 1.3094\n",
            "Epoch 3 Batch 300 Loss 1.2190\n",
            "Epoch 3 Loss 1.2682\n",
            "Time taken for 1 epoch 284.78391218185425 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 1.1454\n",
            "Epoch 4 Batch 100 Loss 1.0302\n",
            "Epoch 4 Batch 200 Loss 0.9996\n",
            "Epoch 4 Batch 300 Loss 0.9924\n",
            "Epoch 4 Loss 1.0716\n",
            "Time taken for 1 epoch 274.4632623195648 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.8929\n",
            "Epoch 5 Batch 100 Loss 0.9717\n",
            "Epoch 5 Batch 200 Loss 0.9392\n",
            "Epoch 5 Batch 300 Loss 0.9437\n",
            "Epoch 5 Loss 0.9245\n",
            "Time taken for 1 epoch 265.88013195991516 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.7737\n",
            "Epoch 6 Batch 100 Loss 0.8193\n",
            "Epoch 6 Batch 200 Loss 0.7829\n",
            "Epoch 6 Batch 300 Loss 0.8528\n",
            "Epoch 6 Loss 0.8029\n",
            "Time taken for 1 epoch 268.4670145511627 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.6635\n",
            "Epoch 7 Batch 100 Loss 0.7535\n",
            "Epoch 7 Batch 200 Loss 0.7295\n",
            "Epoch 7 Batch 300 Loss 0.6963\n",
            "Epoch 7 Loss 0.7000\n",
            "Time taken for 1 epoch 268.06450939178467 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.5422\n",
            "Epoch 8 Batch 100 Loss 0.6141\n",
            "Epoch 8 Batch 200 Loss 0.6246\n",
            "Epoch 8 Batch 300 Loss 0.6426\n",
            "Epoch 8 Loss 0.6076\n",
            "Time taken for 1 epoch 270.37179803848267 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.5230\n",
            "Epoch 9 Batch 100 Loss 0.6714\n",
            "Epoch 9 Batch 200 Loss 0.4991\n",
            "Epoch 9 Batch 300 Loss 0.5263\n",
            "Epoch 9 Loss 0.5273\n",
            "Time taken for 1 epoch 280.6574411392212 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.4263\n",
            "Epoch 10 Batch 100 Loss 0.4280\n",
            "Epoch 10 Batch 200 Loss 0.5308\n",
            "Epoch 10 Batch 300 Loss 0.4367\n",
            "Epoch 10 Loss 0.4542\n",
            "Time taken for 1 epoch 280.3731155395508 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzKsWk-sStpz",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nw9gCFY01lZ2",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "\n",
        "*   We evaluate on the test set.\n",
        "*   In this evaluation, instead of using the concept of teacher forcing, we use the prediction of the decoder as the input to the decoder for the sequence of outputs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1emvSSo0NRbQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "26d70ea6-9bcf-4e89-acb1-bce93812e3ac"
      },
      "source": [
        "start = time.time()\n",
        "\n",
        "encoder.eval()\n",
        "decoder.eval()\n",
        "\n",
        "total_loss = 0\n",
        "\n",
        "final_output = torch.zeros((len(target_tensor_val),max_length_tar))\n",
        "target_output = torch.zeros((len(target_tensor_val),max_length_tar))\n",
        "\n",
        "for (batch, (inp, targ, inp_len)) in enumerate(val_dataset):\n",
        "    loss = 0\n",
        "    xs, ys, lens = sort_batch(inp, targ, inp_len)\n",
        "    enc_output, enc_hidden = encoder(xs.to(device), lens)\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_hidden[0].to(device)\n",
        "    dec_hidden[1].to(device)\n",
        "    \n",
        "    dec_input = torch.tensor([[targ_lang.word2idx['<start>']]] * BATCH_SIZE)\n",
        "    curr_output = torch.zeros((ys.size(0), ys.size(1)))\n",
        "    curr_output[:, 0] = dec_input.squeeze(1)\n",
        "\n",
        "    for t in range(1, ys.size(1)): # run code below for every timestep in the ys batch\n",
        "        predictions, dec_hidden, _ = decoder(dec_input.to(device), \n",
        "                                      dec_hidden, \n",
        "                                      enc_output.to(device))\n",
        "        loss += loss_function(ys[:, t].to(device), predictions.to(device))\n",
        "        dec_input = torch.argmax(predictions, dim=1).unsqueeze(1)\n",
        "        curr_output[:, t] = dec_input.squeeze(1)\n",
        "    final_output[batch*BATCH_SIZE:(batch+1)*BATCH_SIZE] = curr_output\n",
        "    target_output[batch*BATCH_SIZE:(batch+1)*BATCH_SIZE] = targ\n",
        "    batch_loss = (loss / int(ys.size(1)))\n",
        "    total_loss += batch_loss\n",
        "\n",
        "print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                    total_loss / N_BATCH))\n",
        "print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 10 Loss 0.7488\n",
            "Time taken for 1 epoch 25.017688751220703 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQKYT5w3n82V",
        "colab_type": "text"
      },
      "source": [
        "# Bleu Score Calculation for evaluation\n",
        "\n",
        "Read more about Bleu Score at :\n",
        "\n",
        "\n",
        "1.   https://en.wikipedia.org/wiki/BLEU\n",
        "2.   https://www.aclweb.org/anthology/P02-1040.pdf\n",
        "\n",
        "We expect your BLEU Scores to be in the range of for full credit. No partial credit :( \n",
        "\n",
        "\n",
        "*   BLEU-1 > 0.14\n",
        "*   BLEU-2 > 0.08\n",
        "*   BLEU-3 > 0.02\n",
        "*   BLEU-4 > 0.15\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPosimvgdx_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_reference_candidate(target, pred):\n",
        "  reference = list(target)\n",
        "  reference = [targ_lang.idx2word[s] for s in np.array(reference[1:])]\n",
        "  candidate = list(pred)\n",
        "  candidate = [targ_lang.idx2word[s] for s in np.array(candidate[1:])]\n",
        "  return reference, candidate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6NzFQ16fZAc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "96acab21-9f16-439f-97cc-bea324841425"
      },
      "source": [
        "bleu_1 = 0.0\n",
        "bleu_2 = 0.0\n",
        "bleu_3 = 0.0\n",
        "bleu_4 = 0.0\n",
        "smoother = SmoothingFunction()\n",
        "save_candidate = []\n",
        "\n",
        "for i in range(len(target_tensor_val)):\n",
        "  reference, candidate = get_reference_candidate(target_output[i], final_output[i])\n",
        "  #print(reference)\n",
        "  #print(candidate)\n",
        "  save_candidate.append(candidate)\n",
        "\n",
        "  bleu_1 += sentence_bleu(reference, candidate, weights=(1, 0, 0, 0), smoothing_function=smoother.method1)\n",
        "  bleu_2 += sentence_bleu(reference, candidate, weights=(0, 1, 0, 0), smoothing_function=smoother.method2)\n",
        "  bleu_3 += sentence_bleu(reference, candidate, weights=(0, 0, 1, 0), smoothing_function=smoother.method3)\n",
        "  bleu_4 += sentence_bleu(reference, candidate, weights=(0, 0, 0, 1), smoothing_function=smoother.method4)\n",
        "\n",
        "print('Individual 1-gram: %f' % (bleu_1/len(target_tensor_val)))\n",
        "print('Individual 2-gram: %f' % (bleu_2/len(target_tensor_val)))\n",
        "print('Individual 3-gram: %f' % (bleu_3/len(target_tensor_val)))\n",
        "print('Individual 4-gram: %f' % (bleu_4/len(target_tensor_val)))\n",
        "assert(len(save_candidate)==len(target_tensor_val))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Individual 1-gram: 0.152923\n",
            "Individual 2-gram: 0.094136\n",
            "Individual 3-gram: 0.029417\n",
            "Individual 4-gram: 0.181578\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYKSWRO93Mjz",
        "colab_type": "text"
      },
      "source": [
        "# Save File for Submission\n",
        "You just need to submit your **results.pickle** file to the autograder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2Jnt32ItMA7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f578696f-866f-4abe-bdd3-936c26157222"
      },
      "source": [
        "import pickle\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_VdTMfb1M5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('../drive/My Drive/results.pickle', 'wb') as fil:\n",
        "    pickle.dump(save_candidate, fil)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}